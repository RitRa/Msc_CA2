{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twitterscraper\n",
      "  Downloading twitterscraper-1.6.1.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting coala-utils~=0.5.0\n",
      "  Downloading coala_utils-0.5.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: bs4 in /usr/local/anaconda3/lib/python3.7/site-packages (from twitterscraper) (0.0.1)\n",
      "Requirement already satisfied: lxml in /usr/local/anaconda3/lib/python3.7/site-packages (from twitterscraper) (4.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.7/site-packages (from twitterscraper) (2.27.1)\n",
      "Collecting billiard\n",
      "  Downloading billiard-4.0.0-py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.4/86.4 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/anaconda3/lib/python3.7/site-packages (from bs4->twitterscraper) (4.9.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->twitterscraper) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->twitterscraper) (2.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->twitterscraper) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->twitterscraper) (1.26.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->bs4->twitterscraper) (1.9.3)\n",
      "Building wheels for collected packages: twitterscraper\n",
      "  Building wheel for twitterscraper (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for twitterscraper: filename=twitterscraper-1.6.1-py3-none-any.whl size=11346 sha256=0e7422e839abf318a1f6f3387d983e7abb5be99813d1395e3b2a12c37053e552\n",
      "  Stored in directory: /Users/ritaraher/Library/Caches/pip/wheels/aa/93/d2/a941eabe85b81fad5a00529766abaa4611c2f7f2890c350d6d\n",
      "Successfully built twitterscraper\n",
      "Installing collected packages: coala-utils, billiard, twitterscraper\n",
      "Successfully installed billiard-4.0.0 coala-utils-0.5.1 twitterscraper-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install twitterscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7f130e7bfef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtwitterscraper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery_tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlist_of_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trump OR Clinton\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/twitterscraper/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtwitterscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery_tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtwitterscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery_tweets_from_user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtwitterscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery_user_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/twitterscraper/query.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_proxies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0mproxy_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/twitterscraper/query.py\u001b[0m in \u001b[0;36mget_proxies\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'table'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'proxylisttable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mlist_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mlist_td\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'td'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_tr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mlist_td\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_td\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "from twitterscraper import query_tweets\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    list_of_tweets = query_tweets(\"Trump OR Clinton\", 10)\n",
    "\n",
    "    #print the retrieved tweets to the screen:\n",
    "    for tweet in query_tweets(\"Trump OR Clinton\", 10):\n",
    "        print(tweet)\n",
    "\n",
    "    #Or save the retrieved tweets to file:\n",
    "    #file = open(“output.txt”,”w”)\n",
    "    #for tweet in query_tweets(\"Trump OR Clinton\", 10):\n",
    "        #file.write(str(tweet.text.encode('utf-8')))\n",
    "    #file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
